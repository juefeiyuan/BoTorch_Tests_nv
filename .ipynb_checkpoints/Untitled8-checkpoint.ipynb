{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import tempfile\n",
    "import copy\n",
    "import numpy          as np\n",
    "import numpy.random   as npr\n",
    "import scipy.linalg   as spla\n",
    "import scipy.stats    as sps\n",
    "import scipy.optimize as spo\n",
    "import multiprocessing\n",
    "import ast\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "from torch.distributions import Normal\n",
    "import time\n",
    "\n",
    "\n",
    "import math\n",
    "import scipy.linalg as spla\n",
    "import scipy.optimize as spo\n",
    "import scipy.stats as sps\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import functools\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def target(X):\n",
    "    x1 = X[0]\n",
    "    x2 = X[1]\n",
    "    \n",
    "    result = (x2- (5.1/(4*math.pi*math.pi))*x1*x1 + (5/math.pi)*x1 - 6)**2 + 10*(1 - (1/(8*math.pi)))*torch.cos(x1) + 10\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims = 2))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def train_GP_model(model, likelihood, train_x, train_y, training_iter = 150):\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.parameters()}, ], lr=0.1)\n",
    "\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model, likelihood\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def EI(x, train_y, model, likelihood):\n",
    "\n",
    "    x = x.astype(np.float32)\n",
    "    x = torch.from_numpy(x)\n",
    "    x = x.resize_((1,2))\n",
    "    x = x.to(device)\n",
    "    f_star = torch.min(train_y)\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    f_preds = model(x)\n",
    "    pos_mu = f_preds.mean\n",
    "    pos_var = f_preds.variance\n",
    "    pos_sigma = pos_var.clamp_min(1e-9).sqrt()\n",
    "\n",
    "\n",
    "    W = (f_star - pos_mu)/pos_sigma\n",
    "    normal = Normal(torch.zeros_like(W), torch.ones_like(W))\n",
    "    ucdf = normal.cdf(W)\n",
    "    updf = torch.exp(normal.log_prob(W))\n",
    "    ei = pos_sigma * (updf + W * ucdf)\n",
    "    result = -ei\n",
    "    result = result.cpu().detach().contiguous().double().clone().numpy()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def next_sampling_point(EI, train_y, model, likelihood, bnds, opt_method, maxiter, dtype, device, nRestart =25):\n",
    "\n",
    "\n",
    "    min_value = 1000\n",
    "    point_to_sample = None\n",
    "\n",
    "\n",
    "    objective = functools.partial(EI, train_y = train_y,model = model, likelihood = likelihood)\n",
    "    initial_points = torch.rand(nRestart, 2, dtype=dtype, device=device)*15 + torch.tensor([-5.0, 0.0], dtype=dtype, device=device)\n",
    "    initial_points = initial_points.cpu()\n",
    "    \n",
    "    for i in range(nRestart):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "       \n",
    "        initial_point = initial_points[i]\n",
    "        function_to_optimize = objective\n",
    "\n",
    "        warnings.filterwarnings(\"error\")\n",
    "\n",
    "        res = spo.minimize(function_to_optimize, initial_point, method = optimize_method, \\\n",
    "                               options={'maxiter':maxiter, 'disp': False}, bounds = bnds)  \n",
    "\n",
    "        if res.fun < min_value:\n",
    "            min_value = res.fun\n",
    "            point_to_sample = res.x   \n",
    "#         except:\n",
    "#             continue\n",
    "\n",
    "    point_to_sample = torch.from_numpy(point_to_sample)\n",
    "    point_to_sample = point_to_sample.type(dtype)\n",
    "    point_to_sample = point_to_sample.reshape(1,2)\n",
    "    point_to_sample = point_to_sample.to(device)\n",
    "    return point_to_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float\n",
    "nRestart = 1000\n",
    "optimize_method = 'SLSQP'\n",
    "maxiter = 10000\n",
    "d = 2\n",
    "training_iter = 150\n",
    "print(torch.cuda.get_device_name(device))\n",
    "\n",
    "\n",
    "bnds = [np.array([-5., 10.]), np.array([ 0., 15.])]\n",
    "opt_method = 'SLSQP'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# hypers = {\n",
    "#     'covar_module.base_kernel.lengthscale': torch.tensor(0.3),\n",
    "# }\n",
    "\n",
    "train_x = torch.rand(10, 2, dtype=dtype, device=device)*15 + torch.tensor([-5.0, 0.0], dtype=dtype, device=device)\n",
    "\n",
    "train_y = torch.zeros(train_x.shape[0], dtype=dtype, device=device)\n",
    "for i in range(train_x.shape[0]):\n",
    "    train_y[i] = target(train_x[i,:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 200\n",
    "\n",
    "for i in range(iterations):\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = ExactGPModel(train_x, train_y, likelihood)\n",
    "    model = model.to(device)\n",
    "    likelihood = likelihood.to(device)\n",
    "    model, likelihood = train_GP_model(model, likelihood, train_x, train_y, training_iter)\n",
    "\n",
    "    new_x = next_sampling_point(EI, train_y, model, likelihood, bnds, opt_method, maxiter, dtype, device, nRestart)\n",
    "    new_y = target(new_x[0])\n",
    "    train_x =  torch.cat((train_x, new_x), 0)\n",
    "    train_y = torch.cat((train_y, new_y.reshape(1)), 0)\n",
    "    \n",
    "    print('The iteration number is ', i)\n",
    "    print('Best value is ', train_y.min())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
